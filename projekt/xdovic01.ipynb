{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BAYa class Assignment 2021\n",
    "\n",
    "In this assignment, your task will be to implement and analyze algorithms for inference in probabilistic\n",
    "models described by factor graphs. In particular, you will implement Sum-Product algorithm (or Belief Propagation), Max-Product (Max-Sum) algorithm and Loopy Belief Propagation to infer different probabilities, (marginal) distributions and values of variables for general factor\n",
    "graphs with categorical random variables as described in the slides on [Graphical Models and Inference](http://www.fit.vutbr.cz/study/courses/BAYa/public/prednasky/2-Graphical%20Models.pdf).\n",
    "More detailed information can be found in Chapter 8.4 in [Christopher M. Bishop. 2006. Pattern Recognition and Machine Learning](https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf).\n",
    "\n",
    "The preferred and easiest way of accomplishing this task is to complete this Jupyter Notebook, which already comes\n",
    "with a definition of the probabilistic model that you will work with.\n",
    "If you do not have any experience with Jupyter Notebook, the easiest way to start is to install Anaconda3,\n",
    "run Jupyter Notebook and open this notebook downloaded from [BAYa_Assignment2021.ipynb](http://www.fit.vutbr.cz/study/courses/BAYa/public/notebooks/BAYa_Assignment2021.ipynb).\n",
    "\n",
    "The following cell contains a code with the definition of the probabilistic model for which you will run the inference algorithms. You should not edit this part!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1885,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Names of random variables in our model\n",
    "var_names=['State', 'Age', 'COVID', 'Party', 'Favorite', 'Voting']\n",
    "           \n",
    "#Names of possible values (categories) for each random variables.\n",
    "val_names=[['Texas', 'California', 'NewYork'], #State\n",
    "           ['Young', 'Old'],                   #Age\n",
    "           ['Negative', 'Positive'],           #COVID\n",
    "           ['Democrats', 'Republicans'],       #Party\n",
    "           ['Biden', 'Trump'],                 #Favorite\n",
    "           ['InPerson', 'Postal', 'NotVoting']]#Voting\n",
    "\n",
    "#The above variables with names are introduced just to make up a story around our model. Use these names\n",
    "# to interpret your results, but, in your 'generic' inference algorithms, avoid the use of these variables\n",
    "# and use only the definitions below!\n",
    "\n",
    "#Number of categories for each random variable.\n",
    "ncategories = np.array([len(v) for v in val_names])\n",
    "\n",
    "class Factor:\n",
    "    \"\"\"\n",
    "    Instances of this class represent individual factors in a factor graph.\n",
    "    It is merely a structure of two member variables:\n",
    "    'vars': list of N integers, which are IDs of N random variables that this\n",
    "        factor depends on. These integers can be seen as indices into 'var_names'\n",
    "    'table': potential function of the factor. Since we deal only with categorical\n",
    "        variables, the potential function has the form of an N-dimensional array.\n",
    "        The first dimension corresponds to the first variable in 'vars', the second\n",
    "        dimension to the second variable, etc. The size of each dimension is given\n",
    "        by the number of possible values of the corresponding variable.\n",
    "    \"\"\"\n",
    "    def __init__(self, list_of_variable, potential_function_table):\n",
    "        self.vars = list(list_of_variable)\n",
    "        self.table = np.array(potential_function_table)\n",
    "        \n",
    "        # the number of table dimensions and the number of variables must match\n",
    "        assert(self.table.ndim == len(self.vars))\n",
    "        # the individual dimensions must match with the number of categories of the corresponding variable\n",
    "        assert(np.all(ncategories[self.vars]==self.table.shape))\n",
    "\n",
    "    def __repr__(self):\n",
    "        # An instance of Factor prints/shows as list of variables (both names and IDs) it depends on  \n",
    "        return \"f(\"+','.join([var_names[v]+str(v) for v in self.vars])+\")\"\n",
    "        \n",
    "        \n",
    "\"List of factors defining our complete probabilistic model\"\n",
    "factors = [\n",
    "#         P(State)\n",
    "    Factor([0], [0.3,   # Texas\n",
    "                 0.5,   # California\n",
    "                 0.2]), # NewYork\n",
    "\n",
    "#         P(Age)\n",
    "    Factor([1], [0.6,   # Young\n",
    "                 0.4]), # Old\n",
    "\n",
    "#         P(COVID)\n",
    "    Factor([2], [0.7,   # Negative\n",
    "                 0.3]), # Positive\n",
    "    \n",
    "\n",
    "#                               Texas      California  NewYork\n",
    "#         P(Party|State,Age)   Young,Old   Young,Old   Young.Old\n",
    "    Factor([3,    0,    1],  [[[0.4, 0.2], [0.9, 0.8], [0.8, 0.6]],  # Democrats \n",
    "                              [[0.6, 0.8], [0.1, 0.2], [0.2, 0.4]]]),# Republican\n",
    "\n",
    "#         P(Favorite|Party)    Dem.  Rep.\n",
    "    Factor([4,       3],     [[0.95, 0.2],  # Biden\n",
    "                              [0.05, 0.8]]),# Trump\n",
    "    \n",
    "#                                Democrats   Republicans\n",
    "#         P(Voting|Party,COVID) Neg. Pos.  Neg. Pos. \n",
    "    Factor([5,     3,    2], [[[0.5, 0.0], [0.7, 0.1]], # InPerson \n",
    "                              [[0.4, 0.9], [0.1, 0.4]], # Postal\n",
    "                              [[0.1, 0.1], [0.2, 0.5]]])# None\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above cell, we first introduce names of our random variables and their values to make up some \"story\" around our probabilistic model. Our model \"pretends\" to model the behaviour of a random US citizen during last year's US presidential elections. It contains the following random variables and their categorical values:\n",
    "\n",
    "* State: Does the random person come from 'Texas', 'California' or 'NewYork'? For simplicity, we pretend that the USA does not have more states.  \n",
    "* Age: Is the person 'Young' or 'Old'?\n",
    "* COVID: Is the person COVID 'Positive' or 'Negative'?\n",
    "* Party: Is the person a supporter of 'Democrats' or 'Republicans'?\n",
    "* Favorite: Is the person's preferred presidential candidate 'Biden' or 'Trump'?\n",
    "* Voting: Is the person voting 'InPerson', using 'Postal' vote or 'NotVoting' at all?\n",
    "\n",
    "Next came the definition of the full model as a list of factors. In our model, the factors are taken from a bayesian network (see below). Therefore, each factor represents a (normalized) probability distribution for one of the 6 variables. Such variables are always the first element of 'vars' (see 'vars' in class Factor). If 'vars' has more than\n",
    "one element, then the factor represents a conditional distribution that is conditioned on the remaining variables.\n",
    "\n",
    "The following function 'evaluate_factor' can help us interpret the individual factors. Its arguments are a Factor  instance and values for all the variables that the factor depends on (in the order given by 'vars'). The values are given only as integer IDs of the categories (i.e. second indices into 'val_names') The function evaluates the factor using the values. Finally, using the variable and value names, it prints out a string showing what (conditional) distribution is evaluated using what values and what is the resulting probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1886,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Voting=Postal|Party=Democrats,COVID=Positive) = 0.9\n",
      "P(Voting=NotVoting|Party=Republicans,COVID=Positive) = 0.5\n",
      "P(Favorite=Biden|Party=Republicans) = 0.2\n",
      "P(State=California) = 0.5\n"
     ]
    }
   ],
   "source": [
    "def evaluate_factor(factor, *values):\n",
    "    var_vals = [var_names[var]+'='+val_names[var][val] for var,val in zip(factor.vars, values)]\n",
    "    print(\"P(\"+var_vals[0]+ ('' if len(var_vals)<2 else '|')+(','.join(var_vals[1:]))+\") =\", factor.table[values])\n",
    "\n",
    "evaluate_factor(factors[5], 1, 0, 1)\n",
    "evaluate_factor(factors[5], 2, 1, 1)\n",
    "evaluate_factor(factors[4], 0, 1)\n",
    "evaluate_factor(factors[0], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the examples of evaluated factors above, we can see that\n",
    "* 90% of COVID positive supporters of Democrats choose to vote using postal votes\n",
    "* 50% of COVID positive Republicans choose not to vote at all\n",
    "* 15% of Republicans find Biden to be more acceptable president\n",
    "* 40% of voters are from California\n",
    "\n",
    "Using all the factors, the following code constructs a graph showing the corresponding Bayesian Network. Each node is one variable. For each factor, we create edges into the first variable in 'vars' from all the remaining variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1864,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"201pt\" height=\"188pt\"\n viewBox=\"0.00 0.00 200.94 188.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 184)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-184 196.9441,-184 196.9441,4 -4,4\"/>\n<!-- State -->\n<g id=\"node1\" class=\"node\">\n<title>State</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"28.5975\" cy=\"-162\" rx=\"28.6953\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"28.5975\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">State</text>\n</g>\n<!-- Party -->\n<g id=\"node2\" class=\"node\">\n<title>Party</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"65.5975\" cy=\"-90\" rx=\"29.4969\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"65.5975\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Party</text>\n</g>\n<!-- State&#45;&gt;Party -->\n<g id=\"edge1\" class=\"edge\">\n<title>State&#45;&gt;Party</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M37.5541,-144.5708C41.9171,-136.0807 47.2553,-125.6929 52.0989,-116.2674\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"55.2655,-117.7628 56.7233,-107.2687 49.0395,-114.5633 55.2655,-117.7628\"/>\n</g>\n<!-- Favorite -->\n<g id=\"node4\" class=\"node\">\n<title>Favorite</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"61.5975\" cy=\"-18\" rx=\"40.0939\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"61.5975\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Favorite</text>\n</g>\n<!-- Party&#45;&gt;Favorite -->\n<g id=\"edge3\" class=\"edge\">\n<title>Party&#45;&gt;Favorite</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M64.5881,-71.8314C64.1603,-64.131 63.6516,-54.9743 63.1762,-46.4166\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"66.6698,-46.2037 62.6204,-36.4133 59.6806,-46.592 66.6698,-46.2037\"/>\n</g>\n<!-- Voting -->\n<g id=\"node5\" class=\"node\">\n<title>Voting</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"154.5975\" cy=\"-18\" rx=\"35.194\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"154.5975\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Voting</text>\n</g>\n<!-- Party&#45;&gt;Voting -->\n<g id=\"edge4\" class=\"edge\">\n<title>Party&#45;&gt;Voting</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M83.6079,-75.4297C96.261,-65.1936 113.4064,-51.3231 127.6775,-39.778\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"130.1191,-42.3047 135.6922,-33.2941 125.7164,-36.8626 130.1191,-42.3047\"/>\n</g>\n<!-- Age -->\n<g id=\"node3\" class=\"node\">\n<title>Age</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"102.5975\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"102.5975\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Age</text>\n</g>\n<!-- Age&#45;&gt;Party -->\n<g id=\"edge2\" class=\"edge\">\n<title>Age&#45;&gt;Party</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M93.829,-144.937C89.4695,-136.4537 84.1022,-126.0092 79.2222,-116.513\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"82.2438,-114.7352 74.56,-107.4407 76.0178,-117.9348 82.2438,-114.7352\"/>\n</g>\n<!-- COVID -->\n<g id=\"node6\" class=\"node\">\n<title>COVID</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"154.5975\" cy=\"-90\" rx=\"38.1938\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"154.5975\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">COVID</text>\n</g>\n<!-- COVID&#45;&gt;Voting -->\n<g id=\"edge5\" class=\"edge\">\n<title>COVID&#45;&gt;Voting</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M154.5975,-71.8314C154.5975,-64.131 154.5975,-54.9743 154.5975,-46.4166\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"158.0976,-46.4132 154.5975,-36.4133 151.0976,-46.4133 158.0976,-46.4132\"/>\n</g>\n</g>\n</svg>\n",
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7ff293852a00>"
      ]
     },
     "execution_count": 1864,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from graphviz import Digraph\n",
    "dot = Digraph()\n",
    "dot.edges([(var_names[v] ,var_names[f.vars[0]]) for f in factors for v in f.vars[1:]])\n",
    "dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, our model naively assumes that the probability of being COVID positive does not dependent\n",
    "on the age or the state the person is from.\n",
    "\n",
    "Similarly, we can draw Factor Graph corresponding to our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1865,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"722pt\" height=\"116pt\"\n viewBox=\"0.00 0.00 722.00 116.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 112)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-112 718,-112 718,4 -4,4\"/>\n<!-- State_ -->\n<g id=\"node1\" class=\"node\">\n<title>State_</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"64,-108 0,-108 0,-72 64,-72 64,-108\"/>\n<text text-anchor=\"middle\" x=\"32\" y=\"-86.6\" font-family=\"Times,serif\" font-size=\"13.00\" fill=\"#000000\">f(State0)</text>\n</g>\n<!-- State -->\n<g id=\"node7\" class=\"node\">\n<title>State</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"84\" cy=\"-18\" rx=\"28.6953\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"84\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">State</text>\n</g>\n<!-- State_&#45;&#45;State -->\n<g id=\"edge1\" class=\"edge\">\n<title>State_&#45;&#45;State</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M45.1218,-71.8314C53.4258,-60.3335 64.0746,-45.589 72.1272,-34.4393\"/>\n</g>\n<!-- Age_ -->\n<g id=\"node2\" class=\"node\">\n<title>Age_</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"293.5,-108 234.5,-108 234.5,-72 293.5,-72 293.5,-108\"/>\n<text text-anchor=\"middle\" x=\"264\" y=\"-86.6\" font-family=\"Times,serif\" font-size=\"13.00\" fill=\"#000000\">f(Age1)</text>\n</g>\n<!-- Age -->\n<g id=\"node8\" class=\"node\">\n<title>Age</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"179\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"179\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Age</text>\n</g>\n<!-- Age_&#45;&#45;Age -->\n<g id=\"edge2\" class=\"edge\">\n<title>Age_&#45;&#45;Age</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M242.5509,-71.8314C228.0918,-59.5836 209.2836,-43.652 195.8885,-32.3056\"/>\n</g>\n<!-- COVID_ -->\n<g id=\"node3\" class=\"node\">\n<title>COVID_</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"714,-108 634,-108 634,-72 714,-72 714,-108\"/>\n<text text-anchor=\"middle\" x=\"674\" y=\"-86.6\" font-family=\"Times,serif\" font-size=\"13.00\" fill=\"#000000\">f(COVID2)</text>\n</g>\n<!-- COVID -->\n<g id=\"node9\" class=\"node\">\n<title>COVID</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"649\" cy=\"-18\" rx=\"38.1938\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"649\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">COVID</text>\n</g>\n<!-- COVID_&#45;&#45;COVID -->\n<g id=\"edge3\" class=\"edge\">\n<title>COVID_&#45;&#45;COVID</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M667.6914,-71.8314C663.8727,-60.8334 659.0226,-46.865 655.2199,-35.9134\"/>\n</g>\n<!-- Party_ -->\n<g id=\"node4\" class=\"node\">\n<title>Party_</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"216,-108 82,-108 82,-72 216,-72 216,-108\"/>\n<text text-anchor=\"middle\" x=\"149\" y=\"-86.6\" font-family=\"Times,serif\" font-size=\"13.00\" fill=\"#000000\">f(Party3,State0,Age1)</text>\n</g>\n<!-- Party_&#45;&#45;State -->\n<g id=\"edge5\" class=\"edge\">\n<title>Party_&#45;&#45;State</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M132.5978,-71.8314C122.0673,-60.1668 108.5203,-45.1609 98.4054,-33.9568\"/>\n</g>\n<!-- Party_&#45;&#45;Age -->\n<g id=\"edge6\" class=\"edge\">\n<title>Party_&#45;&#45;Age</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M156.5703,-71.8314C161.2222,-60.6667 167.1496,-46.441 171.7426,-35.4177\"/>\n</g>\n<!-- Party -->\n<g id=\"node10\" class=\"node\">\n<title>Party</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"318\" cy=\"-18\" rx=\"29.4969\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"318\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Party</text>\n</g>\n<!-- Party_&#45;&#45;Party -->\n<g id=\"edge4\" class=\"edge\">\n<title>Party_&#45;&#45;Party</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M191.6458,-71.8314C223.9142,-58.0839 267.0767,-39.6951 293.6852,-28.359\"/>\n</g>\n<!-- Favorite_ -->\n<g id=\"node5\" class=\"node\">\n<title>Favorite_</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"432,-108 312,-108 312,-72 432,-72 432,-108\"/>\n<text text-anchor=\"middle\" x=\"372\" y=\"-86.6\" font-family=\"Times,serif\" font-size=\"13.00\" fill=\"#000000\">f(Favorite4,Party3)</text>\n</g>\n<!-- Favorite_&#45;&#45;Party -->\n<g id=\"edge8\" class=\"edge\">\n<title>Favorite_&#45;&#45;Party</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M358.3735,-71.8314C349.7501,-60.3335 338.6917,-45.589 330.3295,-34.4393\"/>\n</g>\n<!-- Favorite -->\n<g id=\"node11\" class=\"node\">\n<title>Favorite</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"406\" cy=\"-18\" rx=\"40.0939\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"406\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Favorite</text>\n</g>\n<!-- Favorite_&#45;&#45;Favorite -->\n<g id=\"edge7\" class=\"edge\">\n<title>Favorite_&#45;&#45;Favorite</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M380.5796,-71.8314C385.7731,-60.8334 392.3693,-46.865 397.5409,-35.9134\"/>\n</g>\n<!-- Voting_ -->\n<g id=\"node6\" class=\"node\">\n<title>Voting_</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"615.5,-108 450.5,-108 450.5,-72 615.5,-72 615.5,-108\"/>\n<text text-anchor=\"middle\" x=\"533\" y=\"-86.6\" font-family=\"Times,serif\" font-size=\"13.00\" fill=\"#000000\">f(Voting5,Party3,COVID2)</text>\n</g>\n<!-- Voting_&#45;&#45;COVID -->\n<g id=\"edge11\" class=\"edge\">\n<title>Voting_&#45;&#45;COVID</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M562.2717,-71.8314C581.8699,-59.6669 607.3229,-43.8686 625.578,-32.5378\"/>\n</g>\n<!-- Voting_&#45;&#45;Party -->\n<g id=\"edge10\" class=\"edge\">\n<title>Voting_&#45;&#45;Party</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M466.6769,-71.9442C433.3966,-62.3072 392.6771,-49.6352 357,-36 351.8453,-34.03 346.4119,-31.6948 341.2917,-29.3703\"/>\n</g>\n<!-- Voting -->\n<g id=\"node12\" class=\"node\">\n<title>Voting</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"533\" cy=\"-18\" rx=\"35.194\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"533\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Voting</text>\n</g>\n<!-- Voting_&#45;&#45;Voting -->\n<g id=\"edge9\" class=\"edge\">\n<title>Voting_&#45;&#45;Voting</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M533,-71.8314C533,-61 533,-47.2876 533,-36.4133\"/>\n</g>\n</g>\n</svg>\n",
      "text/plain": [
       "<graphviz.graphs.Graph at 0x7ff29c7a6b50>"
      ]
     },
     "execution_count": 1865,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from graphviz import Graph\n",
    "fg = Graph()\n",
    "for f in factors:\n",
    "    #fg.node(var_names[f.vars[0]]+\"_\", var_names[f.vars[0]]+\" \"+str(f), shape=\"box\")\n",
    "    fg.node(var_names[f.vars[0]]+\"_\", str(f), shape=\"box\", fontsize=\"13\")\n",
    "fg.edges([(var_names[f.vars[0]]+\"_\" ,var_names[v]) for f in factors for v in f.vars])\n",
    "fg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The factor (rectangle) node names are shown in the form as provided by Factor.\\__repr__() method. Therefore, whenever printing or viewing an instance of a factor node (e.g. for debugging), it will appear in this form of list of variables (both names and IDs) that the factor depends on. This Factor Graph has tree structure so application of Belief Propagation should be straightforward.\n",
    "\n",
    "The following cell implements the inefficient 'brute-force marginalization' approach, which will be useful for testing  correctness of your Belief Propagation implementation. When calling this function, we can specify values of some of the variables and the function marginalizes over all possible values of the remaining variables. It implements the operation\n",
    " $$\n",
    "\\DeclareMathOperator{\\xx}{\\mathbf{x}}\n",
    "\\sum_{\\xx_{marg}}\\prod_s f_s(\\xx_s)\n",
    "$$\n",
    "where the product is over all factors $f_s$, $\\xx_s$ is the subset of variables that $f_s$ depends on and $\\xx_{marg}$ is the subset of variables for which the sum sums over all their possible values (i.e marginalizes). As was already said, in our model, each factor corresponds to the (conditional) distribution of one variable. Therefore, their product corresponds to the joint distribution of all the variables\n",
    "$$\n",
    "\\prod_s f_s(\\xx_s) = P(State) P(Age) P(COVID) P(Party|State,Age) P(Favorite|Party) P(Voting|Party,COVID)\\\\\n",
    "= P(State,Age,COVID,Party,Favorite,Voting)\n",
    "$$\n",
    "\n",
    "For example, if we supply the function with values for $Party$ and $Voting$ and marginalize over all other variables, we obtain the joint marginal probability\n",
    "\n",
    "\n",
    "$$\n",
    "P(Party,Voting)=\\sum_{State} \\sum_{Age}\\sum_{COVID}\\sum_{Favorite}P(State,Age,COVID,Party,Favorite,Voting)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1866,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z =  0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "import itertools    \n",
    "def brute_force_marginalize(value_list):\n",
    "    \"\"\"\n",
    "    observed_values is a list of values one for each variable. For values set to None,\n",
    "    we marginalize over all possible values of the corresponding variable. For other\n",
    "    values, we use the given value for the corresponding variables when evaluating factors.\n",
    "    \"\"\"\n",
    "    value_ranges = [range(n) if v is None else (v,) for n,v in zip(ncategories, value_list)]\n",
    "    marginal_prob = 0.0\n",
    "    # itertools.product let us iterate over all possible values of all variables\n",
    "    for values in itertools.product(*value_ranges):\n",
    "        joint_prob = 1.0\n",
    "        for f in factors:\n",
    "           joint_prob *= f.table[tuple(values[v] for v in f.vars)]\n",
    "        marginal_prob+=joint_prob\n",
    "    return marginal_prob\n",
    "\n",
    "print(\"Z = \", brute_force_marginalize([None, None, None, None, None, None]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When calling **brute_force_marginalize** in the cell above, we set the values of all variables to **None**. This instructs the function to sum over all the values of all the variables. The result is 1, which proves that our model represents a well normalized joint distribution. In the following calls, we clamp some of the variables to specific values, which avoids marginalization over those variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1867,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Voting=InPerson)  = 0.4061000000000001\n",
      "P(Voting=Postal)    = 0.43120000000000014\n",
      "P(Voting=NotVoting) = 0.1627\n",
      "P(Party=Democrats)  = 0.6699999999999997\n",
      "P(Party=Republicans)= 0.33000000000000024\n",
      "P(Party=Republicans,Voting=InPerson)= 0.17159999999999995\n"
     ]
    }
   ],
   "source": [
    "print(\"P(Voting=InPerson)  =\", brute_force_marginalize([None, None, None, None, None, 0]))\n",
    "print(\"P(Voting=Postal)    =\", brute_force_marginalize([None, None, None, None, None, 1]))\n",
    "print(\"P(Voting=NotVoting) =\", brute_force_marginalize([None, None, None, None, None, 2]))\n",
    "print(\"P(Party=Democrats)  =\", brute_force_marginalize([None, None, None, 0, None, None]))\n",
    "print(\"P(Party=Republicans)=\", brute_force_marginalize([None, None, None, 1, None, None]))\n",
    "print(\"P(Party=Republicans,Voting=InPerson)=\", brute_force_marginalize([None, None, None, 1, None, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above examples show that the marginal probabilities $P(Voting)$ and $P(Party)$ sum to 1 when summed over all their possible values. The marginal distribution $P(Voting)$ tells us what are the probabilities of different forms of voting (InPerson, Postal, NotVoting) and $P(Party=Democrats)$ says that $2/3$ of all the people are Democrats. \n",
    "\n",
    "We also evaluate the joint marginal P(Party,Voting) to see that out of all the people, 17.16% are Republicans that came to vote InPerson.\n",
    "\n",
    "# Simple implementation of Belief Propagation algorithm\n",
    "As a quick start, here comes a simple implementation of the Belief Propagation (or Sum-Product) algorithm, which infers marginal distribution for only one variable. Your task will be to extend this code in various ways according to the tasks and questions below.\n",
    "\n",
    "First, from our factor graph, we create a topologically sorted list of arcs going from leaf nodes to a selected root node. This defines the order in which the messages in the belief propagation algorithm needs to be evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1868,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(f(State0), 0),\n",
       " (0, f(Party3,State0,Age1)),\n",
       " (f(Age1), 1),\n",
       " (1, f(Party3,State0,Age1)),\n",
       " (f(Party3,State0,Age1), 3),\n",
       " (4, f(Favorite4,Party3)),\n",
       " (f(Favorite4,Party3), 3),\n",
       " (3, f(Voting5,Party3,COVID2)),\n",
       " (f(COVID2), 2),\n",
       " (2, f(Voting5,Party3,COVID2)),\n",
       " (f(Voting5,Party3,COVID2), 5)]"
      ]
     },
     "execution_count": 1868,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtain list of topologically sorted arcs (paths from the leaves to the root node)\n",
    "# by recursively calling down_the_tree() function starting from a selected root node\n",
    "topologically_sorted_arcs=[]\n",
    "def down_the_tree(to_node, from_node):\n",
    "    neighbours = to_node.vars if type(to_node) is Factor else [f for f in factors if to_node in f.vars]\n",
    "    for node in neighbours:\n",
    "        if node != from_node:\n",
    "            down_the_tree(node, to_node)\n",
    "            topologically_sorted_arcs.append((node, to_node))\n",
    "\n",
    "# We select variable node 5 as the root node\n",
    "down_the_tree(5, None)\n",
    "\n",
    "topologically_sorted_arcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the result of this step is a list of (from_node, to_node) tuples. Each tuple contains one factor node (instance of class Factor) and one variable node (integer ID) saying from which node to which node given arc leads.\n",
    "\n",
    "Next we define function **evaluate_message(from_node, to_node, message_dict)**, which evaluates message from node **from_node**, to node **to_node** using already evaluated messages stored in dictionary **message_dict** and stores the new message also to dictionary **message_dict**. This function simply implements the two main formulas of the Belief Propagation algorithm:\n",
    "$$\n",
    "\\mu_{x_m\\rightarrow f_s}(x_m) = \\prod_{l \\in ne(x_m)\\setminus f_s} \\mu_{f_l\\rightarrow x_m}(x_m)\n",
    "$$\n",
    "$$\n",
    "\\mu_{f_s\\rightarrow x_n}(x_n)=\\sum_{\\mathbf{x}_s\\setminus x_n }f_s(\\mathbf{x}_s) \\prod_{m \\in ne(f_s)\\setminus x_n}\\mu_{x_m\\rightarrow f_s}(x_m)\n",
    "$$\n",
    "It selects the right formula depending on the type of the evaluated message (from factor to variable node or the other way around). It also covers the initial values for the leaf nodes where $\\mu_{f\\rightarrow x}(x)=f(x)$ and $\\mu_{x\\rightarrow f}(x)=1$.\n",
    "\n",
    "Next we call **evaluate_message** in a loop to evaluate all the (topologically sorted) messages from the leaves to the selected root."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1869,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(f(State0), 0): array([0.3, 0.5, 0.2]),\n",
       " (0, f(Party3,State0,Age1)): array([0.3, 0.5, 0.2]),\n",
       " (f(Age1), 1): array([0.6, 0.4]),\n",
       " (1, f(Party3,State0,Age1)): array([0.6, 0.4]),\n",
       " (f(Party3,State0,Age1), 3): array([0.67, 0.33]),\n",
       " (4, f(Favorite4,Party3)): array([1., 1.]),\n",
       " (f(Favorite4,Party3), 3): array([1., 1.]),\n",
       " (3, f(Voting5,Party3,COVID2)): array([0.67, 0.33]),\n",
       " (f(COVID2), 2): array([0.7, 0.3]),\n",
       " (2, f(Voting5,Party3,COVID2)): array([0.7, 0.3]),\n",
       " (f(Voting5,Party3,COVID2), 5): array([0.4061, 0.4312, 0.1627])}"
      ]
     },
     "execution_count": 1869,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate_message(from_node, to_node, message_dict):\n",
    "    # Message from variable to factor (i.e. the first formula above)\n",
    "    if type(to_node) is Factor: \n",
    "        msg_values=np.ones(ncategories[from_node])\n",
    "        var_node_neighbours = [f for f in factors if from_node in f.vars] # Find neighbouring factor nodes\n",
    "        for fac in var_node_neighbours:          # Retrieve messages (vectors) from all neighbour nodes\n",
    "            if fac != to_node:                              # except for the target factor node\n",
    "                msg_values *= message_dict[(fac, from_node)]# and calculate their product as the new message.\n",
    "                \n",
    "    # Message from factor to variable (i.e. the first formula above)\n",
    "    else:\n",
    "        # We need to multiply the messages (vectors) coming from the neighbouring variable nodes to the corresponding\n",
    "        # dimensions of the factor table and marginalize these dimensions out (i.e. sum over these dimensions).\n",
    "        # This is done by calling np.tensordot in the code below once for each dimension/message. However,\n",
    "        # we need to skip the dimension/variable corresponding to the target variable (to_node). To do that,\n",
    "        # we move this dimension to be the last dimension in the np.array representing the factor table.\n",
    "        msg_values = np.moveaxis(from_node.table, from_node.vars.index(to_node), -1)\n",
    "        for var in from_node.vars:                          # Retrieve messages (vectors) from all neighbour nodes\n",
    "            if var != to_node:                              # except for the target variable node\n",
    "                msg_values = np.tensordot(msg_values, message_dict[(var, from_node)], axes=([0],[0]))\n",
    "                                                            # and evaluate the new message (to the target node).\n",
    "        \"\"\"\"\n",
    "        # An alternative more explicit implementation of the 'else' branch\n",
    "        msg_values = np.moveaxis(from_node.table, from_node.vars.index(to_node), 0)\n",
    "        for var in from_node.vars[::-1]: # Go through the variables (and the incoming messages) in the reverse order. ...\n",
    "            if var != to_node:\n",
    "                msg_values = np.sum(msg_values * message_dict[(var, from_node)], axis=-1)\n",
    "                # ... Then the first message corresponds with the last dimension of 'msg_values'. We multiply\n",
    "                # the message to the last dimension of 'msg_values' and marginalize (sum) it out. The last dimension\n",
    "                # disappears and the next message is ready to be multiplied to the new last dimension.\n",
    "        \"\"\"\n",
    "                    \n",
    "    message_dict[(from_node, to_node)] = msg_values # Store the new message\n",
    "\n",
    "messages={}\n",
    "for from_node, to_node in topologically_sorted_arcs:\n",
    "    evaluate_message(from_node, to_node, messages)\n",
    "    \n",
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the result of this step is a dictionary of all the evaluated messages. The keys are the (from_node, to_node) tuples identifying the arcs as before and the values are the corresponding messages (vectors).\n",
    "\n",
    "Finally, we define function **marginal4var(var, message_dict)**, which evaluates the marginal distribution for variable **var**, using the messages stored in the dictionary **message_dict**. Of course, it is possible only if all the messages necessary to evaluate this distribution are present in the dictionary. In our case, we only evaluated messages leading to the root node corresponding to variable \"Voting\" (variable ID 5). Therefore, we can call this function only for this node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1870,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Voting) = [0.4061 0.4312 0.1627] \n",
      "\n",
      "P(Voting=0)= 0.4061000000000001\n",
      "P(Voting=1)= 0.43120000000000014\n",
      "P(Voting=2)= 0.1627 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def marginal4var(var, message_dict):\n",
    "    res = np.prod([message_dict[k] for k in message_dict.keys() if k[1] == var], axis=0)\n",
    "    return res / np.sum(res)\n",
    "\n",
    "print(\"P(Voting) =\", marginal4var(5, messages),\"\\n\")\n",
    "print(\"P(Voting=0)=\", brute_force_marginalize([None, None, None, None, None, 0]))\n",
    "print(\"P(Voting=1)=\", brute_force_marginalize([None, None, None, None, None, 1]))\n",
    "print(\"P(Voting=2)=\", brute_force_marginalize([None, None, None, None, None, 2]),\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that calling **marginal4var** for variable \"Voting\" gives us its correct marginal distribution as verified using function **brute_force_marginalize**.\n",
    "\n",
    "# Tasks and Questions\n",
    "Your task is to extend the above code to answer questions in the following points. Please comment your code sufficiently. It will be taken into account when evaluating the project. Describe what, why and how are you trying to implement. Try to reuse the existing code or its structure as much as possible. Please, do not implement complex general classes and functions with lots of parameters and branches trying to address all the problems and answer all the questions. Instead, write simple single purpose streamlined code addressing a single problem at a time. If you need to implement simple modification of already existing function, do not be afraid to copy-paste that function and modify it. Then explain in comments, what modification you did and why. Try to make your code as little cryptic and as easy to follow as possible.\n",
    "\n",
    "\n",
    "1\\. For all the individual variables, use the Sum-Product  algorithm to (most efficiently) infer and print their marginal distributions $P(State)$, $P(Age)$, $P(COVID)$, $P(Party)$, $P(Favorite)$, $P(Voting)$. We already evaluated marginal distributions for variable $Voting$ in the code above where we used functions **evaluate_message** and **marginal4var**. Reuse these functions as they are to evaluate all the marginal distributions. Check their correctness using the **brute_force_marginalize** function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1871,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BP  |P(Voting) = [0.4061 0.4312 0.1627]\n",
      "BFM |P(Voting=InPerson) = 0.4061000000000001\n",
      "BFM |P(Voting=Postal) = 0.43120000000000014\n",
      "BFM |P(Voting=NotVoting) = 0.1627\n",
      "\n",
      "BP  |P(Party) = [0.67 0.33]\n",
      "BFM |P(Party=Democrats) = 0.6699999999999997\n",
      "BFM |P(Party=Republicans) = 0.33000000000000024\n",
      "\n",
      "BP  |P(State) = [0.3 0.5 0.2]\n",
      "BFM |P(State=Texas) = 0.29999999999999993\n",
      "BFM |P(State=California) = 0.5000000000000001\n",
      "BFM |P(State=NewYork) = 0.19999999999999998\n",
      "\n",
      "BP  |P(Age) = [0.6 0.4]\n",
      "BFM |P(Age=Young) = 0.6\n",
      "BFM |P(Age=Old) = 0.4000000000000002\n",
      "\n",
      "BP  |P(Favorite) = [0.7025 0.2975]\n",
      "BFM |P(Favorite=Biden) = 0.7024999999999998\n",
      "BFM |P(Favorite=Trump) = 0.2975\n",
      "\n",
      "BP  |P(COVID) = [0.7 0.3]\n",
      "BFM |P(COVID=Negative) = 0.7\n",
      "BFM |P(COVID=Positive) = 0.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def belief_propagation(to_node: int, from_node: int, messages: dict, topologically_sorted_nodes: list) -> None:\n",
    "    neighbours = to_node.vars if type(to_node) is Factor else [f for f in factors if to_node in f.vars]\n",
    "    for node in neighbours:\n",
    "        if node != from_node:\n",
    "            # saving nodes (from root to leafs - preorder)\n",
    "            topologically_sorted_nodes.append((to_node, node))\n",
    "            belief_propagation(node, to_node, messages, topologically_sorted_nodes)\n",
    "            # evaluate current node (from leafs to root - postorder)\n",
    "            evaluate_message(node, to_node, messages)\n",
    "\n",
    "def bp_all_marginals(topologically_sorted_nodes: list, messages: dict, marginals: dict) -> None:\n",
    "    for (from_node, to_node) in topologically_sorted_nodes:\n",
    "        # evaluate missing marginals\n",
    "        evaluate_message(from_node, to_node, messages)\n",
    "        if (type(from_node) is Factor):\n",
    "            # if to_node is variable node, save marignal probability of variable\n",
    "            marginals[to_node] = marginal4var(to_node, messages)\n",
    "\n",
    "# message container   \n",
    "messages = {}\n",
    "# sorted nodes container (order according to tree traversal)\n",
    "topologically_sorted_nodes=[]\n",
    "# select variable node 5 as the root node\n",
    "root_marginal = belief_propagation(5, None, messages, topologically_sorted_nodes)\n",
    "# marginals container\n",
    "marginals = {5: messages.popitem()[1]}\n",
    "bp_all_marginals(topologically_sorted_nodes, messages, marginals)\n",
    "\n",
    "for var, probs in marginals.items():\n",
    "    print(\"BP  |P({}) = {}\".format(var_names[var], probs))\n",
    "    vars = [None, None, None, None, None, None]\n",
    "    \n",
    "    for i in range(ncategories[var]):\n",
    "        vars[var] = i\n",
    "        print(\"BFM |P({}={}) =\".format(var_names[var], val_names[var][i]), brute_force_marginalize(vars))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. What is the computational complexity of the inference from the previous point compared to the brute-force marginalization? Extend the code for the inference algorithms (both brute-force and Sum-Product) to count the number of additions and multiplications carried out during the inference (consider only those from the equations describing the algorithm). Report these numbers. Note that, with the brute-force approach you need to call the brute_force_marginalize once for every value of every variable in order to evaluate all the marginal distributions. Note also that single call of **np.tensordot** in function **evaluate_message** performs many multiplications and additions. You need to count all of them. Similarly, when calculating the product of two messages, it is an element-wise product of several numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1872,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brute_force_marginalize_cnt(value_list):\n",
    "    \"\"\"\n",
    "    observed_values is a list of values one for each variable. For values set to None,\n",
    "    we marginalize over all possible values of the corresponding variable. For other\n",
    "    values, we use the given value for the corresponding variables when evaluating factors.\n",
    "    \"\"\"\n",
    "    # counter of multiplications and additions\n",
    "    n_operations = 0\n",
    "\n",
    "    value_ranges = [range(n) if v is None else (v,) for n,v in zip(ncategories, value_list)]\n",
    "    marginal_prob = 0.0\n",
    "    # itertools.product let us iterate over all possible values of all variables\n",
    "    for values in itertools.product(*value_ranges):\n",
    "        joint_prob = 1.0\n",
    "        for f in factors:\n",
    "           joint_prob *= f.table[tuple(values[v] for v in f.vars)]\n",
    "           # plus one multiplication\n",
    "           n_operations += 1\n",
    "        marginal_prob+=joint_prob\n",
    "        # plus one addition\n",
    "        n_operations += 1\n",
    "    return marginal_prob, n_operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1873,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_message_cnt(from_node, to_node, message_dict):\n",
    "    # counter of multiplications and additions\n",
    "    n_operations = 0\n",
    "    \n",
    "    if type(to_node) is Factor: \n",
    "        msg_values=np.ones(ncategories[from_node])\n",
    "        var_node_neighbours = [f for f in factors if from_node in f.vars]\n",
    "        for fac in var_node_neighbours:\n",
    "            if fac != to_node:\n",
    "                # number of multiplications == number of categories of variable from which is\n",
    "                # factor computed\n",
    "                n_operations += msg_values.size - 1\n",
    "                msg_values *= message_dict[(fac, from_node)]\n",
    "    else:\n",
    "        # An alternative more explicit implementation of the 'else' branch\n",
    "        msg_values = np.moveaxis(from_node.table, from_node.vars.index(to_node), 0)\n",
    "        for var in from_node.vars[::-1]: # Go through the variables (and the incoming messages) in the reverse order. ...\n",
    "            if var != to_node:\n",
    "                msg_values = np.sum(msg_values * message_dict[(var, from_node)], axis=-1)\n",
    "                # number of multiplications == number of table cells\n",
    "                # number of additions == (number of factors of current variable node minus one) times\n",
    "                # (multiplication of numbers of categories of variables current variable depends)\n",
    "                n_operations += msg_values.size + np.prod(np.flip(msg_values.shape)[1:]) * (ncategories[var] - 1)\n",
    "\n",
    "    message_dict[(from_node, to_node)] = msg_values # Store the new message\n",
    "\n",
    "    return n_operations\n",
    "\n",
    "\n",
    "def marginal4var_cnt(var, message_dict):\n",
    "    prob_vecs = [message_dict[k] for k in message_dict.keys() if k[1] == var]\n",
    "    res = np.prod(prob_vecs, axis=0)\n",
    "\n",
    "    # number of multiplications == (number of incomming messages minus one) times (number of\n",
    "    # categories of variable)\n",
    "    n_operations = (len(prob_vecs) - 1) * ncategories[var]\n",
    "    return res / np.sum(res), n_operations + 1 + len(res) - 1\n",
    "\n",
    "\n",
    "def belief_propagation_cnt(to_node: int, from_node: int, messages: dict, topologically_sorted_nodes: list, n_operations: int) -> None:\n",
    "    neighbours = to_node.vars if type(to_node) is Factor else [f for f in factors if to_node in f.vars]\n",
    "    for node in neighbours:\n",
    "        if node != from_node:\n",
    "            # saving nodes (from root to leafs)\n",
    "            topologically_sorted_nodes.append((to_node, node))\n",
    "            n_operations += belief_propagation_cnt(node, to_node, messages, topologically_sorted_nodes, n_operations)\n",
    "            # evaluate current node (from leafs to root)\n",
    "            n_operations += evaluate_message_cnt(node, to_node, messages)\n",
    "    return n_operations\n",
    "\n",
    "\n",
    "def bp_all_marginals_cnt(topologically_sorted_nodes: list, messages: dict, marginals: dict) -> None:\n",
    "    n_operations = 0\n",
    "\n",
    "    for (from_node, to_node) in topologically_sorted_nodes:\n",
    "        # evaluate missing marginals\n",
    "        n_operations += evaluate_message_cnt(from_node, to_node, messages)\n",
    "        if (type(from_node) is Factor):\n",
    "            # if to_node is variable node, save marignal probability of variable\n",
    "            marginals[to_node], n_ops = marginal4var_cnt(to_node, messages)\n",
    "            n_operations += n_ops\n",
    "\n",
    "    return n_operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1874,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total additions and multiplications\n",
      "-----------------------------------\n",
      "Brut Force Marginalization |   6048\n",
      "Belief Propagation         |    281\n"
     ]
    }
   ],
   "source": [
    "total_operations_bfm = 0\n",
    "for var in range(len(var_names)):\n",
    "    vars = [None, None, None, None, None, None]\n",
    "    for i in range(ncategories[var]):\n",
    "        vars[var] = i\n",
    "        _, n_ops = brute_force_marginalize_cnt(vars)\n",
    "        total_operations_bfm += n_ops\n",
    "\n",
    "tmp1 = {}\n",
    "tmp2 = []\n",
    "tmp3 = {}\n",
    "total_operations_bp = 0\n",
    "total_operations_bp += belief_propagation_cnt(5, None, tmp1, tmp2, 0)\n",
    "total_operations_bp += bp_all_marginals_cnt(tmp2, tmp1, tmp3)\n",
    "\n",
    "print(\"Total additions and multiplications\")\n",
    "print(\"-----------------------------------\")\n",
    "print(\"Brut Force Marginalization |  \", total_operations_bfm)\n",
    "print(\"Belief Propagation         |   \", total_operations_bp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Implement function **jointmarginal4fact** similar to already implemented function **marginal4var**. However, this function gets an instance of Factor as the first parameter and evaluates joint marginal distribution for all the variables that the factor depends on. Use this function to evaluate and print joint marginal distributions $P(Favorite, Party)$ and $P(Voting,Party,COVID)$. Check their correctness using the **brute_force_marginalize** function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1875,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Belief Propagation\n",
      "-----------------------------------------\n",
      "P(Favorite=0,Party=0) = 0.6365000000000001\n",
      "P(Favorite=1,Party=0) = 0.13400000000000004\n",
      "P(Favorite=0,Party=1) = 0.0165\n",
      "P(Favorite=1,Party=1) = 0.264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denis/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:87: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    }
   ],
   "source": [
    "def jointmarginal4fact(fac, message_dict):\n",
    "    assert(type(fac) is Factor)\n",
    "    return fac.table * np.moveaxis(np.prod(np.ix_(*(message_dict[k] for k in message_dict.keys() if k[0] in fac.vars and k[1] == fac))), -1, 0)\n",
    "\n",
    "\n",
    "fp = jointmarginal4fact(factors[4], messages)\n",
    "\n",
    "print(\"Belief Propagation\")\n",
    "print(\"-----------------------------------------\")\n",
    "print(\"P(Favorite=0,Party=0) =\", fp[0][0])\n",
    "print(\"P(Favorite=1,Party=0) =\", fp[0][1])\n",
    "print(\"P(Favorite=0,Party=1) =\", fp[1][0])\n",
    "print(\"P(Favorite=1,Party=1) =\", fp[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1876,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Voting=0,Party=0,COVID=0) = 0.23450000000000004\n",
      "P(Voting=0,Party=0,COVID=1) = 0.0\n",
      "P(Voting=0,Party=1,COVID=0) = 0.16169999999999998\n",
      "P(Voting=0,Party=1,COVID=1) = 0.0099\n",
      "P(Voting=1,Party=0,COVID=0) = 0.18760000000000004\n",
      "P(Voting=1,Party=0,COVID=1) = 0.18090000000000003\n",
      "P(Voting=1,Party=1,COVID=0) = 0.0231\n",
      "P(Voting=1,Party=1,COVID=1) = 0.0396\n"
     ]
    }
   ],
   "source": [
    "vpc = jointmarginal4fact(factors[5], messages)\n",
    "\n",
    "print(\"P(Voting=0,Party=0,COVID=0) =\", vpc[0][0][0])\n",
    "print(\"P(Voting=0,Party=0,COVID=1) =\", vpc[0][0][1])\n",
    "print(\"P(Voting=0,Party=1,COVID=0) =\", vpc[0][1][0])\n",
    "print(\"P(Voting=0,Party=1,COVID=1) =\", vpc[0][1][1])\n",
    "print(\"P(Voting=1,Party=0,COVID=0) =\", vpc[1][0][0])\n",
    "print(\"P(Voting=1,Party=0,COVID=1) =\", vpc[1][0][1])\n",
    "print(\"P(Voting=1,Party=1,COVID=0) =\", vpc[1][1][0])\n",
    "print(\"P(Voting=1,Party=1,COVID=1) =\", vpc[1][1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1877,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Brute Force Marginalization\n",
      "-----------------------------------------\n",
      "P(Favorite=0,Party=0) = 0.6364999999999998\n",
      "P(Favorite=1,Party=0) = 0.066\n",
      "P(Favorite=0,Party=1) = 0.0335\n",
      "P(Favorite=1,Party=1) = 0.264\n",
      "P(Voting=0,Party=0,COVID=0) = 0.2345\n",
      "P(Voting=0,Party=0,COVID=1) = 0.0\n",
      "P(Voting=0,Party=1,COVID=0) = 0.16169999999999998\n",
      "P(Voting=0,Party=1,COVID=1) = 0.009899999999999999\n",
      "P(Voting=1,Party=0,COVID=0) = 0.18760000000000002\n",
      "P(Voting=1,Party=0,COVID=1) = 0.1809\n",
      "P(Voting=1,Party=1,COVID=0) = 0.023100000000000002\n",
      "P(Voting=1,Party=1,COVID=1) = 0.039599999999999996\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBrute Force Marginalization\")\n",
    "print(\"-----------------------------------------\")\n",
    "print(\"P(Favorite=0,Party=0) =\", brute_force_marginalize([None, None, None, 0, 0, None]))\n",
    "print(\"P(Favorite=1,Party=0) =\", brute_force_marginalize([None, None, None, 1, 0, None]))\n",
    "print(\"P(Favorite=0,Party=1) =\", brute_force_marginalize([None, None, None, 0, 1, None]))\n",
    "print(\"P(Favorite=1,Party=1) =\", brute_force_marginalize([None, None, None, 1, 1, None]))\n",
    "print(\"P(Voting=0,Party=0,COVID=0) =\", brute_force_marginalize([None, None, 0, 0, None, 0]))\n",
    "print(\"P(Voting=0,Party=0,COVID=1) =\", brute_force_marginalize([None, None, 1, 0, None, 0]))\n",
    "print(\"P(Voting=0,Party=1,COVID=0) =\", brute_force_marginalize([None, None, 0, 1, None, 0]))\n",
    "print(\"P(Voting=0,Party=1,COVID=1) =\", brute_force_marginalize([None, None, 1, 1, None, 0]))\n",
    "print(\"P(Voting=1,Party=0,COVID=0) =\", brute_force_marginalize([None, None, 0, 0, None, 1]))\n",
    "print(\"P(Voting=1,Party=0,COVID=1) =\", brute_force_marginalize([None, None, 1, 0, None, 1]))\n",
    "print(\"P(Voting=1,Party=1,COVID=0) =\", brute_force_marginalize([None, None, 0, 1, None, 1]))\n",
    "print(\"P(Voting=1,Party=1,COVID=1) =\", brute_force_marginalize([None, None, 1, 1, None, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. Implement Max-Product (or Max-Sum) algorithm and use it to infer the most likely setting of all the variables. In other words, find the values for all the variables that maximizes the joint probability $P(State, Age, COVID, Party, Favorite, Voting)$. For this purpose, implement and use function **evaluate_maxproduct_message** similar to already implemented function **evaluate_message**, where sumations (hidden in **np.tensordot**) needs to be replaced by max operation. Note that this is somewhat tricky task and, before introducing the max operation, you may want to first reimplement **evaluate_message** so that **np.tensordot** is reimplemented using nested 'for' loops. The function also needs to store the the information necessary for backtracking. Use the parameter **backtrack_dict** for this purpose. To find the most likely setting of the variables, you will call **evaluate_maxproduct_message** only for messages sent from leaves to a selected variable root node. Then you can evaluate the most likely setting of the root node and backtrack the most likely values of the other variables as described in the [slides](http://www.fit.vutbr.cz/study/courses/BAYa/public/prednasky/2-Graphical%20Models.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1878,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(State=California,Age=Young,COVID=Negative,Party=Democrats,Favorite=Biden,Voting=InPerson) = 0.089775\n"
     ]
    }
   ],
   "source": [
    "def evaluate_maxproduct_message(from_node, to_node, message_dict, backtrack_dict):\n",
    "    assert(type(from_node) is Factor and type(to_node) is int or type(from_node) is int and type(to_node) is Factor)\n",
    "    \n",
    "    if type(to_node) is Factor: \n",
    "        msg_values=np.ones(ncategories[from_node])\n",
    "        var_node_neighbours = [f for f in factors if from_node in f.vars] # Find neighbouring factor nodes\n",
    "        for fac in var_node_neighbours:          # Retrieve messages (vectors) from all neighbour nodes\n",
    "            if fac != to_node:                              # except for the target factor node\n",
    "                msg_values *= message_dict[(fac, from_node)]# and calculate their product as the new message.\n",
    "                \n",
    "    else:\n",
    "        msg_values = np.moveaxis(from_node.table, from_node.vars.index(to_node), 0)\n",
    "        for var in from_node.vars[::-1]: # Go through the variables (and the incoming messages) in the reverse order. ...\n",
    "            if var != to_node:\n",
    "                msg_values = np.max(msg_values * message_dict[(var, from_node)], axis=-1) # propagating maximal probability of\n",
    "                                                                                          # settings (calculating probabilty of\n",
    "                                                                                          # most likely setting)\n",
    "        backtrack_dict[(from_node, to_node)] = np.argmax(msg_values, axis=-1) # Store setting that maximize probability of variable\n",
    "                             \n",
    "    message_dict[(from_node, to_node)] = msg_values # Store the new message\n",
    "\n",
    "\n",
    "def max_product(to_node: int, from_node: int, messages: dict, backtrack: dict) -> None:\n",
    "    neighbours = to_node.vars if type(to_node) is Factor else [f for f in factors if to_node in f.vars]\n",
    "    for node in neighbours:\n",
    "        if node != from_node:\n",
    "            max_product(node, to_node, messages, backtrack)\n",
    "            # evaluate current node (from leafs to root)\n",
    "            evaluate_maxproduct_message(node, to_node, messages, backtrack)\n",
    "\n",
    "\n",
    "messages = {}\n",
    "backtrack = {}\n",
    "max_product(5, None, messages, backtrack)\n",
    "\n",
    "\n",
    "str_prob = \"P(\"\n",
    "for idx, (_, value) in enumerate(backtrack.items()):\n",
    "    str_prob += var_names[idx] + \"=\" + val_names[idx][value] + (\",\" if idx < len(vars) - 1 else \"\")\n",
    "str_prob += \") = \" + str(np.max(messages.popitem()[1]))\n",
    "\n",
    "print(str_prob)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. Implement function **brute_force_one_best** which finds the most likely setting of all variables using the bruteforce approach (i.e. by evaluating joint probability of all variables for all possible settings of the variables). This can be easily achieved by modifying/simplifying function **brute_force_marginalize**. Use this function to check that your implementation of the  Max-Product algorithm is correct. How does the most likely setting of all variables compare to the most likely values according to marginal distributions of the individual variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1879,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(State=California,Age=Young,COVID=Negative,Party=Democrats,Favorite=Biden,Voting=InPerson) = 0.089775\n"
     ]
    }
   ],
   "source": [
    "def brute_force_one_best():\n",
    "    # most likely setting - (probabilty of setting, setting)\n",
    "    most_likely = (0, [])\n",
    "    # itertools.product let us iterate over all possible values of all variables\n",
    "    value_ranges = [range(n) for n in ncategories]\n",
    "    for values in itertools.product(*value_ranges):\n",
    "        joint_prob = 1.0\n",
    "        # calculate joint probaility of current setting\n",
    "        for f in factors:\n",
    "            joint_prob *= f.table[tuple(values[v] for v in f.vars)]\n",
    "        # maximizing most likely setting\n",
    "        if joint_prob > most_likely[0]:\n",
    "            most_likely = (joint_prob, values)\n",
    "    return most_likely\n",
    "\n",
    "# evaluate most likley setting\n",
    "prob, setting = brute_force_one_best()\n",
    "\n",
    "str_prob = \"P(\"\n",
    "for idx, value in enumerate(setting):\n",
    "    str_prob += var_names[idx] + \"=\" + val_names[idx][value] + (\",\" if idx < len(vars) - 1 else \"\")\n",
    "str_prob += \") = \" + str(prob)\n",
    "print(str_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. In the following code cell, we change our factor graph by redefining the factors corresponding to the distributions for variables $Age$ and $COVID$. These factors will now represent conditional distributions $P(Age|State)$ and $P(COVID|State)$ (i.e. the variables are newly conditioned on variable $State$) to express that the ratios of Old/Young people and COVID positive/negative people are different in different states. Please, display the Bayesian Network and the Factor Graph for this updated model and identify a loop in the Factor Graph to show it does not have a tree structure anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1880,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not change this field!\n",
    "\n",
    "#                  P(Age|State) Texas California NewYork\n",
    "factors[1] = Factor([1,  0],   [[0.7,    0.5,     0.4], # Young\n",
    "                                [0.3,    0.5,     0.6]])# Old\n",
    "\n",
    "#                  P(COVID|State) Texas California NewYork\n",
    "factors[2] = Factor([2,    0],   [[0.55,     0.7,     0.6], # Negative\n",
    "                                  [0.45,     0.3,     0.4]])# Positive\n",
    "\n",
    "#ATTENTION! After executing this code, you need to invalidate/recalculate variables like 'topologically_sorted_arcs'\n",
    "# or 'messages' as they contain references to the old (now invalid) factor instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1881,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"180pt\" height=\"260pt\"\n viewBox=\"0.00 0.00 179.64 260.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 256)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-256 175.643,-256 175.643,4 -4,4\"/>\n<!-- State -->\n<g id=\"node1\" class=\"node\">\n<title>State</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"95.2964\" cy=\"-234\" rx=\"28.6953\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"95.2964\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">State</text>\n</g>\n<!-- Age -->\n<g id=\"node2\" class=\"node\">\n<title>Age</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"40.2964\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"40.2964\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Age</text>\n</g>\n<!-- State&#45;&gt;Age -->\n<g id=\"edge1\" class=\"edge\">\n<title>State&#45;&gt;Age</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M82.8161,-217.6621C75.784,-208.4564 66.8617,-196.7764 59.0081,-186.4953\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"61.5792,-184.0953 52.7274,-178.2733 56.0165,-188.3446 61.5792,-184.0953\"/>\n</g>\n<!-- COVID -->\n<g id=\"node3\" class=\"node\">\n<title>COVID</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"133.2964\" cy=\"-90\" rx=\"38.1938\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"133.2964\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">COVID</text>\n</g>\n<!-- State&#45;&gt;COVID -->\n<g id=\"edge2\" class=\"edge\">\n<title>State&#45;&gt;COVID</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M100.0323,-216.0535C106.5177,-191.4774 118.2282,-147.1008 125.8818,-118.0974\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"129.3334,-118.7348 128.5008,-108.1727 122.5651,-116.9487 129.3334,-118.7348\"/>\n</g>\n<!-- Party -->\n<g id=\"node4\" class=\"node\">\n<title>Party</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"43.2964\" cy=\"-90\" rx=\"29.4969\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"43.2964\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Party</text>\n</g>\n<!-- State&#45;&gt;Party -->\n<g id=\"edge3\" class=\"edge\">\n<title>State&#45;&gt;Party</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M93.312,-215.8877C90.8592,-197.33 85.7925,-167.8928 76.2964,-144 72.3811,-134.1488 66.7295,-124.0527 61.2066,-115.2957\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"63.9906,-113.1587 55.5759,-106.721 58.1393,-117.0011 63.9906,-113.1587\"/>\n</g>\n<!-- Age&#45;&gt;Party -->\n<g id=\"edge4\" class=\"edge\">\n<title>Age&#45;&gt;Party</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M41.0535,-143.8314C41.3743,-136.131 41.7558,-126.9743 42.1124,-118.4166\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"45.6098,-118.5503 42.5292,-108.4133 38.6158,-118.2589 45.6098,-118.5503\"/>\n</g>\n<!-- Voting -->\n<g id=\"node6\" class=\"node\">\n<title>Voting</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"133.2964\" cy=\"-18\" rx=\"35.194\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"133.2964\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Voting</text>\n</g>\n<!-- COVID&#45;&gt;Voting -->\n<g id=\"edge7\" class=\"edge\">\n<title>COVID&#45;&gt;Voting</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M133.2964,-71.8314C133.2964,-64.131 133.2964,-54.9743 133.2964,-46.4166\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"136.7965,-46.4132 133.2964,-36.4133 129.7965,-46.4133 136.7965,-46.4132\"/>\n</g>\n<!-- Favorite -->\n<g id=\"node5\" class=\"node\">\n<title>Favorite</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"40.2964\" cy=\"-18\" rx=\"40.0939\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"40.2964\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Favorite</text>\n</g>\n<!-- Party&#45;&gt;Favorite -->\n<g id=\"edge5\" class=\"edge\">\n<title>Party&#45;&gt;Favorite</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M42.5394,-71.8314C42.2185,-64.131 41.837,-54.9743 41.4805,-46.4166\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"44.977,-46.2589 41.0636,-36.4133 37.9831,-46.5503 44.977,-46.2589\"/>\n</g>\n<!-- Party&#45;&gt;Voting -->\n<g id=\"edge6\" class=\"edge\">\n<title>Party&#45;&gt;Voting</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M61.5093,-75.4297C74.3045,-65.1936 91.6425,-51.3231 106.074,-39.778\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"108.5565,-42.2742 114.1788,-33.2941 104.1836,-36.8081 108.5565,-42.2742\"/>\n</g>\n</g>\n</svg>\n",
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7ff293aa17f0>"
      ]
     },
     "execution_count": 1881,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from graphviz import Digraph\n",
    "dot = Digraph()\n",
    "dot.edges([(var_names[v] ,var_names[f.vars[0]]) for f in factors for v in f.vars[1:]])\n",
    "dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1882,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"794pt\" height=\"116pt\"\n viewBox=\"0.00 0.00 793.50 116.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 112)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-112 789.5,-112 789.5,4 -4,4\"/>\n<!-- State_ -->\n<g id=\"node1\" class=\"node\">\n<title>State_</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"330,-108 266,-108 266,-72 330,-72 330,-108\"/>\n<text text-anchor=\"middle\" x=\"298\" y=\"-86.6\" font-family=\"Times,serif\" font-size=\"13.00\" fill=\"#000000\">f(State0)</text>\n</g>\n<!-- State -->\n<g id=\"node7\" class=\"node\">\n<title>State</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"232\" cy=\"-18\" rx=\"28.6953\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"232\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">State</text>\n</g>\n<!-- State_&#45;&#45;State -->\n<g id=\"edge1\" class=\"edge\">\n<title>State_&#45;&#45;State</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M281.3454,-71.8314C270.6529,-60.1668 256.8975,-45.1609 246.6271,-33.9568\"/>\n</g>\n<!-- Age_ -->\n<g id=\"node2\" class=\"node\">\n<title>Age_</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"96,-108 0,-108 0,-72 96,-72 96,-108\"/>\n<text text-anchor=\"middle\" x=\"48\" y=\"-86.6\" font-family=\"Times,serif\" font-size=\"13.00\" fill=\"#000000\">f(Age1,State0)</text>\n</g>\n<!-- Age_&#45;&#45;State -->\n<g id=\"edge3\" class=\"edge\">\n<title>Age_&#45;&#45;State</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M94.431,-71.8314C130.4151,-57.7506 178.8424,-38.8008 207.6018,-27.5471\"/>\n</g>\n<!-- Age -->\n<g id=\"node8\" class=\"node\">\n<title>Age</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"129\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"129\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Age</text>\n</g>\n<!-- Age_&#45;&#45;Age -->\n<g id=\"edge2\" class=\"edge\">\n<title>Age_&#45;&#45;Age</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M68.4397,-71.8314C82.1247,-59.6669 99.8979,-43.8686 112.645,-32.5378\"/>\n</g>\n<!-- COVID_ -->\n<g id=\"node3\" class=\"node\">\n<title>COVID_</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"464,-108 348,-108 348,-72 464,-72 464,-108\"/>\n<text text-anchor=\"middle\" x=\"406\" y=\"-86.6\" font-family=\"Times,serif\" font-size=\"13.00\" fill=\"#000000\">f(COVID2,State0)</text>\n</g>\n<!-- COVID_&#45;&#45;State -->\n<g id=\"edge5\" class=\"edge\">\n<title>COVID_&#45;&#45;State</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M362.0925,-71.8314C328.4667,-57.9173 283.3509,-39.2486 256.0455,-27.9499\"/>\n</g>\n<!-- COVID -->\n<g id=\"node9\" class=\"node\">\n<title>COVID</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"639\" cy=\"-18\" rx=\"38.1938\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"639\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">COVID</text>\n</g>\n<!-- COVID_&#45;&#45;COVID -->\n<g id=\"edge4\" class=\"edge\">\n<title>COVID_&#45;&#45;COVID</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M464.2564,-74.2006C500.8572,-63.9774 548.9376,-50.0038 591,-36 596.9955,-34.0039 603.3575,-31.7305 609.4215,-29.4871\"/>\n</g>\n<!-- Party_ -->\n<g id=\"node4\" class=\"node\">\n<title>Party_</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"248,-108 114,-108 114,-72 248,-72 248,-108\"/>\n<text text-anchor=\"middle\" x=\"181\" y=\"-86.6\" font-family=\"Times,serif\" font-size=\"13.00\" fill=\"#000000\">f(Party3,State0,Age1)</text>\n</g>\n<!-- Party_&#45;&#45;State -->\n<g id=\"edge7\" class=\"edge\">\n<title>Party_&#45;&#45;State</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M193.8695,-71.8314C201.8958,-60.5001 212.1556,-46.0157 220.0105,-34.9263\"/>\n</g>\n<!-- Party_&#45;&#45;Age -->\n<g id=\"edge8\" class=\"edge\">\n<title>Party_&#45;&#45;Age</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M167.8782,-71.8314C159.5742,-60.3335 148.9254,-45.589 140.8728,-34.4393\"/>\n</g>\n<!-- Party -->\n<g id=\"node10\" class=\"node\">\n<title>Party</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"454\" cy=\"-18\" rx=\"29.4969\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"454\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Party</text>\n</g>\n<!-- Party_&#45;&#45;Party -->\n<g id=\"edge6\" class=\"edge\">\n<title>Party_&#45;&#45;Party</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M248.133,-72.2946C305.7579,-57.0968 385.8466,-35.9745 427.0849,-25.0985\"/>\n</g>\n<!-- Favorite_ -->\n<g id=\"node5\" class=\"node\">\n<title>Favorite_</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"602,-108 482,-108 482,-72 602,-72 602,-108\"/>\n<text text-anchor=\"middle\" x=\"542\" y=\"-86.6\" font-family=\"Times,serif\" font-size=\"13.00\" fill=\"#000000\">f(Favorite4,Party3)</text>\n</g>\n<!-- Favorite_&#45;&#45;Party -->\n<g id=\"edge10\" class=\"edge\">\n<title>Favorite_&#45;&#45;Party</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M519.7939,-71.8314C504.9263,-59.6669 485.6171,-43.8686 471.7684,-32.5378\"/>\n</g>\n<!-- Favorite -->\n<g id=\"node11\" class=\"node\">\n<title>Favorite</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"542\" cy=\"-18\" rx=\"40.0939\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"542\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Favorite</text>\n</g>\n<!-- Favorite_&#45;&#45;Favorite -->\n<g id=\"edge9\" class=\"edge\">\n<title>Favorite_&#45;&#45;Favorite</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M542,-71.8314C542,-61 542,-47.2876 542,-36.4133\"/>\n</g>\n<!-- Voting_ -->\n<g id=\"node6\" class=\"node\">\n<title>Voting_</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"785.5,-108 620.5,-108 620.5,-72 785.5,-72 785.5,-108\"/>\n<text text-anchor=\"middle\" x=\"703\" y=\"-86.6\" font-family=\"Times,serif\" font-size=\"13.00\" fill=\"#000000\">f(Voting5,Party3,COVID2)</text>\n</g>\n<!-- Voting_&#45;&#45;COVID -->\n<g id=\"edge13\" class=\"edge\">\n<title>Voting_&#45;&#45;COVID</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M686.8501,-71.8314C676.7779,-60.5001 663.9028,-46.0157 654.0456,-34.9263\"/>\n</g>\n<!-- Voting_&#45;&#45;Party -->\n<g id=\"edge12\" class=\"edge\">\n<title>Voting_&#45;&#45;Party</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M620.4397,-72.4154C581.3147,-63.1611 534.2265,-50.6784 493,-36 487.6608,-34.099 482.0546,-31.7403 476.8103,-29.3632\"/>\n</g>\n<!-- Voting -->\n<g id=\"node12\" class=\"node\">\n<title>Voting</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"730\" cy=\"-18\" rx=\"35.194\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"730\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Voting</text>\n</g>\n<!-- Voting_&#45;&#45;Voting -->\n<g id=\"edge11\" class=\"edge\">\n<title>Voting_&#45;&#45;Voting</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M709.8132,-71.8314C713.9375,-60.8334 719.1756,-46.865 723.2825,-35.9134\"/>\n</g>\n</g>\n</svg>\n",
      "text/plain": [
       "<graphviz.graphs.Graph at 0x7ff293c76970>"
      ]
     },
     "execution_count": 1882,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from graphviz import Graph\n",
    "fg = Graph()\n",
    "for f in factors:\n",
    "    #fg.node(var_names[f.vars[0]]+\"_\", var_names[f.vars[0]]+\" \"+str(f), shape=\"box\")\n",
    "    fg.node(var_names[f.vars[0]]+\"_\", str(f), shape=\"box\", fontsize=\"13\")\n",
    "fg.edges([(var_names[f.vars[0]]+\"_\" ,var_names[v]) for f in factors for v in f.vars])\n",
    "fg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7\\. Since the Factor Graph is not a tree, we cannot use the standard Belief Propagation algorithm for the inference. Therefore, use Loopy Belief Propagation algorithm to infer all marginal distributions $P(State)$, $P(Age)$, $P(COVID)$, $P(Party)$, $P(Favorite)$, $P(Voting)$ for the updated model. Again, reuse the existing functions **evaluate_message** and **marginal4var** and check the correctness of the inferred distributions using the **brute_force_marginalize** function. Note that, because of the loop in the Factor Graph, the message cannot be topologically sorted and an alternative iterative schedule needs to be chosen for evaluating the messages. What schedule for evaluating the messages did you choose? How does it affect the convergence of the algorithm? Note that, to increase numerical stability of the Loopy Belief Propagation algorithm, it is good a idea to normalize each message so that it sums to 1. Such normalization does not change the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1883,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LBP |P(State) = [0.3 0.5 0.2]\n",
      "BFM |P(State=Texas) = 0.3\n",
      "BFM |P(State=California) = 0.49999999999999994\n",
      "BFM |P(State=NewYork) = 0.2\n",
      "\n",
      "LBP |P(Age) = [0.54 0.46]\n",
      "BFM |P(Age=Young) = 0.54\n",
      "BFM |P(Age=Old) = 0.45999999999999985\n",
      "\n",
      "LBP |P(COVID) = [0.635 0.365]\n",
      "BFM |P(COVID=Negative) = 0.635\n",
      "BFM |P(COVID=Positive) = 0.365\n",
      "\n",
      "LBP |P(Party) = [0.661 0.339]\n",
      "BFM |P(Party=Democrats) = 0.6629999999999999\n",
      "BFM |P(Party=Republicans) = 0.33699999999999997\n",
      "\n",
      "LBP |P(Favorite) = [0.69575 0.30425]\n",
      "BFM |P(Favorite=Biden) = 0.69725\n",
      "BFM |P(Favorite=Trump) = 0.30274999999999996\n",
      "\n",
      "LBP |P(Voting) = [0.3729265 0.456053  0.1710205]\n",
      "BFM |P(Voting=InPerson) = 0.37118\n",
      "BFM |P(Voting=Postal) = 0.45396\n",
      "BFM |P(Voting=NotVoting) = 0.17486000000000002\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_list_of_messages():\n",
    "    messages = {}\n",
    "    for f in factors:\n",
    "        for var in f.vars:\n",
    "            # initializing with well normalized values (no need normalization \n",
    "            # after loopy beliefe propagation)\n",
    "            nvals = ncategories[var]\n",
    "            messages[(f, var)] = np.full((nvals,), 1/nvals)\n",
    "            messages[(var, f)] = np.full((nvals,), 1/nvals)\n",
    "    return messages\n",
    "\n",
    "\n",
    "def loopy_beliefe_propagation(messages: dict, num_iter: int):\n",
    "    # aproximate inference (max. iter. condition)\n",
    "    for _ in range(num_iter):\n",
    "        # reevaluation of messages\n",
    "        for (from_node, to_node), _ in messages.items():\n",
    "            evaluate_message(from_node, to_node, messages)\n",
    "\n",
    "\n",
    "def get_all_marginals(messages, marginals):\n",
    "    # computing marginal probabilities for all variables\n",
    "    for (from_node, to_node), _ in messages.items():\n",
    "        if (type(from_node) is Factor):\n",
    "            marginals[to_node] = marginal4var(to_node, messages)\n",
    "\n",
    "\n",
    "messages = get_list_of_messages()\n",
    "loopy_beliefe_propagation(messages, 10)\n",
    "marginals = {}\n",
    "get_all_marginals(messages, marginals)\n",
    "\n",
    "for var, probs in marginals.items():\n",
    "    print(\"LBP |P({}) = {}\".format(var_names[var], probs))\n",
    "    vars = [None, None, None, None, None, None]\n",
    "    for i in range(ncategories[var]):\n",
    "        vars[var] = i\n",
    "        print(\"BFM |P({}={}) =\".format(var_names[var], val_names[var][i]), brute_force_marginalize(vars))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8\\. For our updated model, infer the most likely setting of all the variables using the brute-force approach Use the already implemented **brute_force_one_best** function for this purpose. Note that \"loopy variant\" of the Max-Product algorithm can be also used for this purpose. You might try to implement it and experiment with it to gain some bonus points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1884,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(State=California,Age=Young,COVID=Negative,Party=Democrats,Favorite=Biden,Voting=InPerson) = 0.07481249999999999\n"
     ]
    }
   ],
   "source": [
    "prob, setting = brute_force_one_best()\n",
    "\n",
    "str_prob = \"P(\"\n",
    "for idx, value in enumerate(setting):\n",
    "    str_prob += var_names[idx] + \"=\" + val_names[idx][value] + (\",\" if idx < len(vars) - 1 else \"\")\n",
    "str_prob += \") = \" + str(prob)\n",
    "print(str_prob)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
